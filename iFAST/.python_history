exit()
import pexpect
exit()
import pexpect
exit()
import pexpect
exit()
import paramiko
import subprocess
ssh_connect_command = "sshpass -p {P@ssword1} ssh {a.ravindranath}@{10.100.1.79}" 
ssh_command = f'sshpass -p "Tools@123" scp -rp /opt/vz_raw_data/INVT/07292024/*-topology.csv sieluser@10.100.1.159:/home/sieluser/Topology/07292024'
subprocess.Popen(f"{ssh_connect_command} {ssh_command}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
ssh_connect_command = "sshpass -p P@ssword1 ssh a.ravindranath@10.100.1.79"  
subprocess.Popen(f"{ssh_connect_command} {ssh_command}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
ssh_connect_command = "ssh a.ravindranath@10.100.1.79"  
subprocess.Popen(f"{ssh_connect_command} {ssh_command}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
exit
import paramiko
import os
import pandas as pd
import paramiko
from datetime import datetime
import glob
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%m%d%Y")
today_dir
ssh_command = f'sshpass -p "Tools@123" scp -rp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
ssh_command = f'sshpass -p "Tools@123" scp -rp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
ssh_command
ssh = paramiko.SSHClient()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
source_ip = "10.100.1.79"
source_username = "a.ravindranath"
source_password = "P@ssword1"
ssh.connect(source_ip, username=source_username, password=source_password)
ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(ssh_command)
ssh_stdin
ssh_stdout
ssh.close()
import os
os.chdir("/home/sieluser/Topology/07292024")
os.listdir()
os.system
os.system("rsync -a a.ravindranath@10.100.1.79:/opt/vz_raw_data/INVT/20240729/*-topology.csv /home/sieluser/Topology/07292024")
os.listdir()
len(os.listdir())
import os
os.system('sshpass -p "P@ssword1" rsync -a a.ravindranath@10.100.1.79:/opt/vz_raw_data/INVT/20240729/*-topology.csv /home/sieluser/Topology/07292024') 
import paramiko
import os
ssh = paramiko.SSHClient()
source_ip = "10.100.1.79";source_username = "a.ravindranath";source_password = "P@ssword1"
ssh.connect(source_ip, username=source_username, password=source_password)
client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
command = 'sshpass -p "Tools@123" rsync -a /opt/vz_raw_data/INVT/07292024/*-topology.csv /home/sieluser/Topology/07292024'
stdin, stdout, stderr = client.exec_command(command)
stdin
stdout
stderr
os.listdir(
"/home/sieluser/Topology/07292024")
import os
os.listdir("/home/sieluser/Topology/07292024")
os.chdir("/home/sieluser/Topology/07292024")
import paramiko
client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
command = 'sshpass -p "Tools@123" rsync -a /opt/vz_raw_data/INVT/07292024/*-topology.csv sieluser@10.100.1.159:/home/sieluser/Topology/07292024'
stdin, stdout, stderr = client.exec_command(command)
os.listdir("/home/sieluser/Topology/07292024")
exit
import os
import paramiko
os.chdir("/home/sieluser/Topology/07292024")
client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
command = 'sshpass -p "Tools@123" scp /opt/vz_raw_data/INVT/20240729/*-topology.csv sieluser@10.100.1.159:/home/sieluser/Topology/07292024'
stdin, stdout, stderr = client.exec_command(command)
os.listdir("/home/sieluser/Topology/07292024")
client.close()
import apndas as pd
import pandas as pd
os.listdir()
final_df_list = []
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str)
		final_df_list.append(df)
	except:
		pass
len(final_df_list)
df = pd.concat(final_df_list)
df.shape
df.head(0
)
df.head()
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str, sep ="\t")
		final_df_list.append(df)
final_df_list = []
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str, sep = "\t")
		final_df_list.append(df)
	except:
		pass
df = pd.concat(final_df_list, ignore_index=True)
df
final_df_list = []
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str, sep = "\t")
		df['File_Name"] = f
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str, sep = "\t")
		df['File_Name'] = f
		final_df_list.append(df)
	except:
pass
for f in os.listdir():
	try:
		df = pd.read_csv(f, dtype =str, sep = "\t")
		df['File_Name'] = f
		final_df_list.append(df)
	except:
		pass
df = pd.concat(final_df_list, ignore_index=True)
df.head()
import os
import pandas as pd
from datetime import datetime
import glob
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
	os.chdir(pwd)
	if not today_dir in os.listdir():
		os.mkdirs(today_dir)
	else:
		files = glob.glob(f'{pwd}/{today_dir}*')
		for f in files:
			os.remove(f)
def ssh_gather(cmd_to_execute):
import paramiko
import os
os.getcwd()
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
from datetime import datetime
today_dir = datetime.now().strftime("%Y%m%d")
today_dir
client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}" 
topology_folder
command = f'sshpass -p "Tools@123" scp{topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
command
ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(command)
os.getcwd()
os.listdir()
import os
from datetime import datetime
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
os.chdir(pwd)
today_dir in os.listdir()
files = glob.glob(f'{pwd}/{today_dir}*')
import glob
files = glob.glob(f'{pwd}/{today_dir}*')
files
files = glob.glob(f'{pwd}/{today_dir}/*')
files
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
final_df_list = []
topology_dir = f'{pwd}{today_dir}'
topology_dir
os.listdir(topology_dir)
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
topology_dir = f'{pwd}{today_dir}'
topology_dir
final_df_list = []
for f in os.listdir(topology_dir):
	df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
	df['File_Name'] = f
	final_df_list.append(df)
len(final_df_list)
df_final = pd.concat(final_df_list, ignore_index=True)
df_final.head()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def concat_csv(topology_dir):
	final_df_list = []
	for f in os.listdir(topology_dir):
		try:
			df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
			df['File_Name'] = f
			final_df_list.append(df)
		except:
			pass
	df_final = pd.concat(final_df_list, ignore_index=True)
	return df_final
df_topology = concat_csv(f'{pwd}{today_dir}')
df_topology.head()
x = "Branchburg2A-topology.csv"
x.strip("-topology.csv")
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
	os.chdir(pwd)	
	if not today_dir in os.listdir():
		os.mkdir(today_dir)
	else:
		files = glob.glob(f'{pwd}/{today_dir}/*')
		for f in files:
			os.remove(f)
def ssh_gather(cmd_to_execute):
	client = paramiko.SSHClient()
	client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
	client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
	ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
	client.close()
def transfer_topology_files():
	topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
	command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
	ssh_gather(command)
def concat_csv(topology_dir):
	final_df_list = []
	for f in os.listdir(topology_dir):
		try:
			df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
			df['USM'] = f.strip("-topology.csv")
			final_df_list.append(df)
		except:
			print(f"Unable to read {topology_dir}/{f}")
	df_final = pd.concat(final_df_list, ignore_index=True)
	return df_final
mk_dir()
os.getcwd()
os.listdir()
os.chdir('/home/sieluser/Topology/20240730')
os.listdir()
transfer_topology_files()
os.listdir()
df_topology = concat_csv(f'{pwd}{today_dir}')
df_topology.head()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
def concat_csv(topology_dir):
    final_df_list = []
    for f in os.listdir(topology_dir):
        try:
            df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
            df['File_Name'] = f.strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {topology_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    return df_final
def main():
    mk_dir()
    transfer_topology_files()
    df_topology = concat_csv(f'{pwd}{today_dir}')
    df_topology.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
main()
def main():
...     mk_dir()
...     transfer_topology_files()
def main():
    mk_dir()
    transfer_topology_files()
main?()
main()
os.listdir()
os.listdir(os.getcwd()+"/20240730")
def concat_csv():
    final_df_list = []
    for f in os.listdir(f'{pwd}{today_dir}'):
        try:
            df = pd.read_csv(f"{pwd}{today_dir}/{f}", dtype=str, sep = "\t")
            df['File_Name'] = f.strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {pwd}{today_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    df_final.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
def main():
    mk_dir()
    transfer_topology_files()
    concat_csv()
os.listdir(os.getcwd()+"/20240730")
f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv",
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
def concat_csv():
    final_df_list = []
    for f in os.listdir(f'{pwd}{today_dir}'):
        try:
            df = pd.read_csv(f"{pwd}{today_dir}/{f}", dtype=str, sep = "\t")
            df['File_Name'] = f.strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {pwd}{today_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    df_final.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
def main():
    mk_dir()
    transfer_topology_files()
    concat_csv()
main()
concat_csv()
files = glob.glob(f'{pwd}/{today_dir}/*')
for f in files:	
	os.remove(f)
os.listdir(f'{pwd}/{today_dir}')
main()
os.listdir(f'{pwd}/{today_dir}')
def concat_csv():
    final_df_list = []
    for f in glob.glob(f'{pwd}/{today_dir}/*'):
        try:
            df = pd.read_csv(f, dtype=str, sep = "\t")
            df['File_Name'] = f.split("/")[-1].strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {pwd}{today_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    df_final.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
main()
final_df_list = []
for f in glob.glob(f'{pwd}/{today_dir}/*'):
    try:
        df = pd.read_csv(f, dtype=str, sep = "\t")
        df['File_Name'] = f.split("/")[-1].strip("-topology.csv")
        final_df_list.append(df)
    except:
        print(f"Unable to read {pwd}{today_dir}/{f}")
len(final_df_list)
df_final = pd.concat(final_df_list, ignore_index=True)
df_final.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
os.listdir(f'{pwd}/{today_dir}')
mk_dir()
os.listdir(f'{pwd}/{today_dir}')
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
transfer_topology_files()
os.listdir(f'{pwd}/{today_dir}')
concat_csv()
def concat_csv():
    final_df_list = []
    for f in glob.glob(f'{pwd}/{today_dir}/*'):
        try:
            df = pd.read_csv(f, dtype=str, sep = "\t")
            df['File_Name'] = f.split("/")[-1].strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {pwd}{today_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    df_final.to_csv(f"{pwd}{today_dir}/Combined_Topology_{today_dir}.csv", index=False)
concat_csv()
os.listdir(f'{pwd}/{today_dir}')
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def concat_csv(topology_dir):
    final_df_list = []
    for f in os.listdir(topology_dir):
        try:
            df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
            df['USM'] = f.strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {topology_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    return df_final
mk_dir()
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
mk_dir()
os.lisdir(f'{pwd}/{today_dir}')
os.listdir(f'{pwd}/{today_dir}')
transfer_topology_files()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
transfer_topology_files()
os.listdir(f'{pwd}/{today_dir}')
df_topology = concat_csv(f'{pwd}{today_dir}')
df_topology.head()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
def concat_csv(topology_dir):
    final_df_list = []
    for f in os.listdir(topology_dir):
        try:
            df = pd.read_csv(f"{topology_dir}/{f}", dtype=str, sep = "\t")
            df['USM'] = f.strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {topology_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    return df_final
mk_dir()
transfer_topology_files()
df_topology = concat_csv(f'{pwd}{today_dir}')
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
def concat_csv():
    final_df_list = []
    for f in glob.glob(f'{pwd}/{today_dir}/*'):
        try:
            df = pd.read_csv(f, dtype=str, sep = "\t")
            df['File_Name'] = f.split("/")[-1].strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {pwd}{today_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    return df_final
mk_dir()
transfer_topology_files()
df = concat_csv()
df.head()
os.listdir(f'{pwd}/{today_dir}')
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
for f in glob.glob(f'{pwd}/{today_dir}/*'):
	df = pd.read_csv(f, sep="\t", dtype=str)
	print(f"{f}--------{df.shape}")
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
for f in glob.glob(f'{pwd}/{today_dir}/*'):
	df = pd.read_csv(f, sep="\t", dtype=str)
	print(f"{f}--------{df.shape}")
import os
os.chdir("/home/sieluser/Topology/20240730")
os.listdir()
import os
os.listdir('/home/sieluser/Topology/20240730')
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
mk_dir()
transfer_topology_files()
os.chdir(f"{pwd}/{today_dir}")
os.getcwd()
print(os.getcwd())
print(os.listdir(os.getcwd()))
for f in os.listdir(os.getcwd()):
        print(f)
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
print(os.listdir(f"{pwd}/{today_dir}"))
for f in os.listdir(os.getcwd()):
        print(f)
for f in os.listdir((f"{pwd}/{today_dir}")):
        print(f)
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
def transfer_topology_files():
    topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
    command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
    ssh_gather(command)
os.listdir(f'{pwd}/{today_dir}/')
mk_dir()
os.listdir(f'{pwd}/{today_dir}/')
transfer_topology_files()
os.listdir(f'{pwd}/{today_dir}/')
files = glob.glob(f'{pwd}/{today_dir}/*')
files
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
def ssh_gather(cmd_to_execute):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    # Connect to the source server
    client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
    # Exceute the command
    ssh_stdin, ssh_stdout, ssh_stderr = client.exec_command(cmd_to_execute)
    client.close()
mk_dir()
os.listdir(f'{pwd}/{today_dir}/')
topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
ssh_gather(command)
os.listdir(f'{pwd}/{today_dir}/')
files = glob.glob(f'{pwd}/{today_dir}/*')
print(files)
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
print(os.listdir(f'{pwd}/{today_dir}/'))
def mk_dir():
    os.chdir(pwd)
    if not today_dir in os.listdir():
        os.mkdir(today_dir)
    else:
        files = glob.glob(f'{pwd}/{today_dir}/*')
        for f in files:
            os.remove(f)
mk_dir()
print(os.listdir(f'{pwd}/{today_dir}/'))
topology_folder = f"/opt/vz_raw_data/INVT/{today_dir}"
command = f'sshpass -p "Tools@123" scp {topology_folder}/*-topology.csv sieluser@10.100.1.159:{pwd}{today_dir}'
command
client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
#Connect to the source server
client.connect(hostname='10.100.1.79', username='a.ravindranath', password='P@ssword1')
#Exceute the command
client.exec_command(command)
client.close()
print(os.listdir(f'{pwd}/{today_dir}/'))
import pandas as pd
import os
os.getcwd()
df = pd.read_csv("Combined_Topology_20240730.csv", dtype=str)
df.head()
import pyodbc
import sqlalchemy
pymysql
import pymysql
Host = "localhost"
# User name of the database server
User = "admin"
# Password for the database user
#Password = decryptPWD.decryptPWD()
Password = "@DBadmin123"
# database = "audit_report"
conn = pymysql.connect(host=Host, user=User, password=Password, database="audit_report")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
conn = pymysql.connect(host='10.100.1.159', user=User, password=Password, database="iFast")
conn = pymysql.connect(host='tcp:10.100.1.159', user=User, password=Password, database="iFast")
import pymysql
Host = "10.100.1.69"
User = "admin"
# Password for the database user
#Password = decryptPWD.decryptPWD()
Password = "@DBadmin123"
User
Password
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFast")
conn = pymysql.connect(host=f"tcp:{Host}", user=User, password=Password, database="iFast")
import pymysql
User = "admin"
# Password for the database user
#Password = decryptPWD.decryptPWD()
Password = "@DBadmin123"
conn = pymysql.connect(host="10.100.1.69", user=User, password=Password, database="audit_report")
cur = conn.cursor()
query = """SELECT TABLE_NAME
FROM INFORMATION_SCHEMA.TABLES
WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_CATALOG='dbName'"""
cur.execute(query)
output = cur.fetchall() 
for i in output:
	print(i)
conn = pymysql.connect(host="10.100.1.69", user=User, password=Password, database="iFAST")
conn = pymysql.connect(host="127.0.0.1", user=User, password=Password, database="iFAST")
query = "SELECT * FROM iFAST.action_steps;"
cur = conn.cursor()
cur.execute(query)
output = cur.fetchall()
for i in output:
	print(i)
import pandas as pd
import polars
os.getcwd()
import os
os.getcwd()
os.listdir()
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
df['ne-id'] = df['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
import re
df['ne-id'] = df['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
df.head()
df[df['ne-id'].isnumeric()]
df['ne-id']= df['ne-id'].apply(pd.to_numeric(), errors='coerce')
pd.to_numeric(df['ne-id'], errors='coerce').notnull().all()
def sub_mrkt(ne_type,ne_id):
    if ne_type == "gnb_cu_cp":
        return ne_id.zfill(9)[:3]
    elif ne_type == "gnb_cu_cnf":
        return ne_id.zfill(11)[:3]
    elif ne_type == "gnb_cu_up":
        return ne_id.zfill(9)[:3]
    elif ne_type == "gnb_au":
        return ne_id.zfill(11)[:3]
    elif ne_type == "gnb_au_sc":
        return ne_id.zfill(11)[:3]
    elif ne_type == "c_fsu":
        return ne_id.zfill(6)[:3]
    elif ne_type == "macro_indoor_dist":
        return ne_id.zfill(6)[:3]
    elif ne_type == "udu_cnf":
        return ne_id.zfill(11)[:3]
    elif ne_type == "vhac":
        return ne_id.zfill(9)[:3]
    else:
        return None
df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df['Market'] = df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df.head()
def sub_mrkt(ne_type,ne_id):
    if ne_type == "gnb_cu_cp":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_cu_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_cu_up":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_au":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_au_sc":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "c_fsu":
        return str(int(ne_id.zfill(6)[:3]))
    elif ne_type == "macro_indoor_dist":
        return str(int(ne_id.zfill(6)[:3]))
    elif ne_type == "udu_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "vhac":
        return str(int(ne_id.zfill(9)[:3]))
    else:
        return None
df['Market'] = df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df.head()
sub_mkt_dict = {'CTX': ['131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '184'],
            'NYM': ['78', '79', '80', '81', '82', '83', '84', '85', '378', '380', '384', '528', '780', '789', '790', '799', '800', '809', '810', '819', '820', '829', '840', '849', '850', '859', '878'],
            'TRI': ['86', '87', '88', '89', '90', '91', '96', '97', '98', '99', '100', '101', '102'],
            'HGC': ['120', '121', '122', '123', '124', '125', '126', '127', '129', '420', '421', '426', '427'],
            'SOC': ['180', '181', '182', '185', '186', '781', '782', '785'],
            'OPW': ['229', '232', '241', '242', '243', '244', '245', '246', '247', '250', '251', '252', '253', '254', '255', '553', '545', '546', '550'],
            'WBV': ['106', '107', '109', '110', '111', '112', '113', '114', '115', '116', '117', '406', '407', '409', '411', '412', '413', '414', '416', '417', '713', '715'],
            'NE': ['56', '57', '58', '59', '60', '61', '62', '64', '65', '66', '68'],
            'UPNY': ['70', '71', '72', '73', '74'],
            'SACR': ['31', '36'],
            'GAAL': ['170', '172', '173', '174'], 
            'ILWI': ['202'],  
            'SCAL': ['47']}
def def_market(x):
    try:
       return [k for k,v in sub_mkt_dict.items() if x in v][0]
    except IndexError:
        return None
df['Region'] = df['Market'].apply(lambda x: def_market(x))
df.head()
df.drop(['ne-id'], axis=1, inplace=True)
df.head()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
os.getcwd()
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Cobined_Topology_20240731.csv", dtype=str)
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFast")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFast")
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
conn.close()
conn
df.head()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
os.getcwd()
os.listdir()
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
df['Market'].unique()
df[df['Market']=='700']
df[df['NE_TyPE']=='c_fsu']
df[df['NE_TYPE']=='c_fsu']
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
df['Market'].unique()
df[df['market'].isna()
]
df[df['Market'].isna()]
df_topology = df.copy()
df_topology['ne-id'] = df_topology['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
df['ne-id'] = df['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
df[df['Market'].isna()]
 df['Market1'] = df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df['Market1'] = df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
def sub_mrkt(ne_type,ne_id):
    if ne_type == "gnb_cu_cp":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_cu_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_cu_up":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_au":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_au_sc":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "c_fsu":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "macro_indoor_dist":
        return str(int(ne_id.zfill(6)[:3]))
    elif ne_type == "udu_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "vhac":
        return str(int(ne_id.zfill(9)[:3]))
    else:
        return None
df['Market1'] = df.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df[df['Market'].isna()]
sub_mrkt('gnb_du_cnf', '5690012012')
len('5690012012')
df['NE_TYPE'].unique((
))
df['NE_TYPE'].unique()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
df[df['Market'].isna()]
df['Market'].unique()
df['Region'].unique()
df[df['Region'].isna()]
df.loc[df['Market']=='0']
df[df['Region'].isna()]['Market'].unique()
df.loc[df['Market']=='371']
df.loc[df['Market']=='0', 'ne-id'] = df.loc[df['Market']=='0', 'NE_NAME'].apply(lambda x: re.search(r"(\d+)_?",x).group(1))
df.loc[df['Market']=='0']
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
df['Market'].unique()
df['Region'].unique()
df[df['Region'].isna()
]
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
df.drop(["ne-id"], axis=1, inplace=True)
datetime.now()
datetime.now().strftime("%Y%m%d-")
etime.now().strftime("%Y%m%d-")
datetime.now().strftime("%Y%m%d %H:%M:%S")
df['Modified Time'] = datetime.now().strftime("%Y%m%d %H:%M:%S")
write_query =f'insert into [dbo].[{table_name}] valu ({("?,"*len(df.columns)).rstrip(",")})'
write_query =f'insert into iFAST.Topology_Test values ({("?,"*len(df.columns)).rstrip(",")})'
cur.executemany(write_query,df.values.tolist())
df.replace([nan], [nONe
nce([nan], [NonE
df = df.replace([nan], [None])
df.fillna("", inplace=True)
df = df.replace([""], [None])
cur.executemany(write_query,df.values.tolist())
cur.executemany(write_query,df.loc[10].values.tolist())
cur.executemany(write_query,df.loc[:10].values.tolist())
cur.executemany(write_query,df.loc[0].values.tolist())
df.loc[0]
len(df.columns)
write_query,df.loc[0].values.tolist()
write_query =f'insert ignore into Topology_Test values ({("?,"*len(df.columns)).rstrip(",")})'
cur.executemany(write_query,df.loc[0].values.tolist())
df.loc[
]
df.loc[0]
df.loc[0, "ENB_TYPE"] = "\N"
df.loc[0, "ENB_TYPE"] = "\\N"
write_query,df.loc[0].values.tolist()
df.loc[0, "ENB_TYPE"] = ""
cur.executemany(write_query,df.loc[0].values.tolist())
cur.executemany(write_query,["","","","","","","","","","","","",""])
df.loc[0]
df.loc[0, 'ENB_TYPE'] = None
df['Modified Time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
df.head()
write_query =f'insert into Topology_Test values ({("?,"*len(df.columns)).rstrip(",")})'
cur.executemany(write_query,df.values.tolist())
cur.executemany(write_query,df.loc[0].values.tolist())
df.loc[0]
df.loc[0, 'ENB_TYPE']
df.loc[0, 'ENB_TYPE'] = ""
cur.executemany(write_query,df.loc[0].values.tolist())
df.loc[0].value.to_list()
df.loc[0].values.to_list()
df.loc[0].values.tolist()
write_query,df.loc[0].values.tolist()
write_query =f'insert into iFAST.Topology_Test values ({("?,"*len(df.columns)).rstrip(",")})'
write_query,df.loc[0].values.tolist()
write_query,df.loc[0].values
write_query,df.loc[0].values.set()
write_query,df.loc[0].values.totuple()
query = ('insert into iFAST.Topology_Test values (?,?,?,?,?,?,?,?,?,?,?,?,?)', ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40'))
cur.execute(query)
query = ('insert into iFAST.Topology_Test values (?,?,?,?,?,?,?,?,?,?,?,?,?)', ['ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40'])
cur.execute(query)
query = 'Insert into iFAST.Topology_Test values (?,?,?,?,?,?,?,?,?,?,?,?,?)', ['ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40']
cur.execute(query)
cur.execute('SELECT * FROM Topology_Test;)
cur.execute('SELECT * FROM Topology_Test;')
cur.execute('INSERT INTO Topology_Test VALUES ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', ')
cur.execute("INSERT INTO Topology_Test VALUES ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40')
cur.execute("insert into Topology_Test VALUES ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40')
cur.execute("insert into Topology_Test VALUES ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40'")
cur.execute("insert into Topology_Test VALUES ('ACPF_56000100', 'ACPF_56000100', '0560001_5GNB_WSBO_ACPFP_056000100', 'gnb_cu_cp', 'v23_B_0', '', '0', '/560001/560066/', 'r_0200', 'Branchburg2A', '56', 'NE', '2024-07-31 16:47:40')")
import os
os.getcwd()
os.listdir()
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
import pandas as pd
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240731.csv", dtype=str)
df.head()
from datetime import datetime
df['Modified Time'] = Combined_Topology_Files
df['Modified Time'] = datetime.now().strftime("%Y%m%d %H:%M:%S")
df.head
df.drop(["ne-id"], axis=1, inplace=True)
df.shape
import glob
import paramiko
import time
import pymysql
import re
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
cur
write_query =f'insert into iFAST.Topology_Test values ({("%s,"*len(df.columns)).rstrip(",")})'
row = df.loc[0].values.tolist()
row
cur.executemany(write_query, rows)
cur.executemany(write_query, row)
write_query
del_query = "TRUNCATE TABLE iFAST.Topology_Test"
cur.execute(del_query)
write_query =(f'insert into iFAST.Topology_Test values ({("%s,"*len(df.columns)).rstrip(",")})')
cur.executemany(write_query, row)
for i, row in df.iterrows():
	if i ==0;
for i, row in df.iterrows():
	if i ==0:
		print(tuple(row))
cols = "`,`".join([str(i) for i in df.columns.tolist()])
cols
df.rename(columns={'Modified Time': 'Modified_Time'}, inplace=True)
cols = "`,`".join([str(i) for i in df.columns.tolist()])
cols
sql = "INSERT INTO `book_details` (`" +cols + "`) VALUES (" + "%s,"*(len(row)-1) + "%s)"
sql
sql = "INSERT INTO `Topology_Test` (`" +cols + "`) VALUES (" + "%s,"*(len(row)-1) + "%s)"
cur.execute(sql, tuple(row))
row
tuple(row)
df.fillna("", inplace=True)
for i, row in df.iterrows():
	if i ==0:
		print(tuple(row))
row
for i, row in df.iterrows():
	if i ==0:
		break
row
tuple(row)
cur.execute(sql, tuple(row))
df.columns
df['Modified_Time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
for i, row in df.iterrows():
	if i ==0:
		break
tuple(row)
cur.execute(sql, tuple(row))
cur.executemany(sql, df.values.tolist())
conn
conn.close()
cur.executemany(sql, df.values.tolist())
df.head()
df['NE_UNIQUE_ID'].value_counts()
df[df['NE_UNIQUE_ID']=='ACPF_56000100']
df['NE_NAME'].value_counts()
df[df['NE_NAME']=='1170654_5GNB_CHNT_ACPFP_117065400']
df = df.drop_duplicates(subset = ["NE_NAME"])
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
cur = conn.cursor()
sql
cur.executemany(sql, df.values.tolist())
df.loc[7]
df.loc[7, 'GNB_ID']
len(df.loc[7, 'GNB_ID'])
conn.close()
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
cur = conn.cursor()
cur.execute(del_query)
cur.executemany(sql, df.values.tolist())
conn.close()
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
cur = conn.cursor()
cur.execute("SELECT * FROM iFAST.Topology_Test LIMIT 100")
output = cur.fetchall()
for i in output:
	print(i)
df.values.tolist()
sql
conn.close()
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
cur = conn.cursor()
write_query = (f'INSERT IGNORE INTO iFAST.Topology_Test VALUES ({("%s,"*len(df_topology.columns)).rstrip(",")})')
write_query = (f'INSERT IGNORE INTO iFAST.Topology_Test VALUES ({("%s,"*len(df.columns)).rstrip(",")})')
write_query
cur.executemany(write_query, df.values.tolist())
conn.commit()
del_query
cur.execute(del_query)
conn.commit()
import pandas as pd
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str)
df.head()
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str, sep = "\t)
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str, sep = "\t")
df.head()
df.loc[df['NE_ID']=="FSU_56020001"]
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str)
df.loc[df['NE_ID'].str.contains("FSU_56020001")]
df.head()
df.columns
df.columns[0]
df.loc[df[df.columns[0]].str.contains("FSU_56020001")]
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str, sep = "\t")
df.head()
df.loc[df['NE_ID'].str.contains("FSU_56020001")]
df.loc[5182, 'NE_NAME']
df.loc[5182, 'NE_NAME'].strip("\t")
df.loc[5182, 'NE_NAME'].strip("\\t")
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str, sep = "\\t")
df = pd.read_csv("Branchburg2A-topology.csv", dtype=str, sep = "\\t", engine="python")
df.head()
df.loc[5182, 'NE_NAME']
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
# Topology Files Storage
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
def concat_csv(topology_dir):
    final_df_list = []
    for f in glob.glob(f'{topology_dir}/*'):
        try:
            df = pd.read_csv(f, dtype=str, sep = "\t")
            df['USM'] = f.split("/")[-1].strip("-topology.csv")
            final_df_list.append(df)
        except:
            print(f"Unable to read {topology_dir}/{f}")
    df_final = pd.concat(final_df_list, ignore_index=True)
    df_final['NE_NAME'] = df_final['NE_NAME'].apply(lambda x: x.strip("\\t"))
    return df_final
def sub_mrkt(ne_type,ne_id):
    if ne_type == "gnb_cu_cp":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_du_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_cu_up":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "gnb_au":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "gnb_au_sc":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "c_fsu":
        return str(int(ne_id.zfill(9)[:3]))
    elif ne_type == "macro_indoor_dist":
        return str(int(ne_id.zfill(6)[:3]))
    elif ne_type == "udu_cnf":
        return str(int(ne_id.zfill(11)[:3]))
    elif ne_type == "vhac":
        return str(int(ne_id.zfill(9)[:3]))
    else:
        return None
df_topology = concat_csv(f'{pwd}{today_dir}')
df_topology['ne-id'] = df_topology['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
df_topology['Market'] = df_topology.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df_topology.loc[df_topology['Market']=='0', 'ne-id'] = df_topology.loc[df_topology['Market']=='0', 'NE_NAME'].apply(lambda x: re.search(r"(\d+)_?",x).group(1))
df_topology['Market'] = df_topology.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df_topology['Region'] = df_topology['Market'].apply(lambda x: def_market(x))
df_topology.drop(['ne-id'], axis=1, inplace=True)
df_topology['Modified_Time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
df_topology.fillna("", inplace=True)
sub_mkt_dict = {'CTX': ['131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '184'],
            'NYM': ['78', '79', '80', '81', '82', '83', '84', '85', '378', '380', '384', '528', '780', '789', '790', '799', '800', '809', '810', '819', '820', '829', '840', '849', '850', '859', '878'],
            'TRI': ['86', '87', '88', '89', '90', '91', '96', '97', '98', '99', '100', '101', '102'],
            'HGC': ['120', '121', '122', '123', '124', '125', '126', '127', '129', '420', '421', '426', '427'],
            'SOC': ['180', '181', '182', '185', '186', '781', '782', '785'],
            'OPW': ['229', '232', '241', '242', '243', '244', '245', '246', '247', '250', '251', '252', '253', '254', '255', '553', '545', '546', '550'],
            'WBV': ['106', '107', '109', '110', '111', '112', '113', '114', '115', '116', '117', '406', '407', '409', '411', '412', '413', '414', '416', '417', '713', '715'],
            'NE': ['56', '57', '58', '59', '60', '61', '62', '64', '65', '66', '68'],
            'UPNY': ['70', '71', '72', '73', '74'],
            'SACR': ['31', '36'],
            'GAAL': ['170', '172', '173', '174'], 
            'ILWI': ['202'],  
            'SCAL': ['47']}
def def_market(x):
    try:
       return [k for k,v in sub_mkt_dict.items() if x in v][0]
    except IndexError:
        return None
df_topology = concat_csv(f'{pwd}{today_dir}')
df_topology['ne-id'] = df_topology['NE_ID'].apply(lambda x: re.search(r"\d+",x).group())
df_topology['Market'] = df_topology.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
    df_topology.loc[df_topology['Market']=='0', 'ne-id'] = df_topology.loc[df_topology['Market']=='0', 'NE_NAME'].apply(lambda x: re.search(r"(\d+)_?",x).group(1))
df_topology.loc[df_topology['Market']=='0', 'ne-id'] = df_topology.loc[df_topology['Market']=='0', 'NE_NAME'].apply(lambda x: re.search(r"(\d+)_?",x).group(1))
df_topology['Market'] = df_topology.apply(lambda x: sub_mrkt(x['NE_TYPE'], x['ne-id']), axis=1)
df_topology['Region'] = df_topology['Market'].apply(lambda x: def_market(x))
df_topology
df_topology['NE_NAME'].value_counts()
df.loc[df['NE_NAME']=='1170654_5GNB_CHNT_AUPFP_117065410']
df_topology.loc[df['NE_NAME']=='1170654_5GNB_CHNT_AUPFP_117065410']
df_topology.loc[df_topology['NE_NAME']=='1170654_5GNB_CHNT_AUPFP_117065410']
vc =df_topology['NE_NAME'].value_counts()
vc>1
vc[vc>1]
vc[vc>1].index
df.loc[vc[vc>1].index]
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index])]
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)]
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)].groupby('NE_NAME')['USM']
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)].groupby('NE_NAME')['USM'].apply(lambda x: list(x))
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)].groupby('NE_NAME')['USM'].apply(lambda x: list(x)).to_table()
df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)].groupby('NE_NAME')['USM'].apply(lambda x: list(x)).totable()
print(df_topology.loc[df_topology['NE_NAME'].isin(vc[vc>1].index)].groupby('NE_NAME')['USM'].apply(lambda x: list(x)))
def valuecounts(df, col1, col2):
    vc =df[col1].value_counts()
    return df.loc[df[col1].isin(vc[vc>1].index)].groupby(col1)[col2].apply(lambda x: list(x))
valuecounts(df_topology, 'NE_NAME', 'USM')
df_vc = valuecounts(df_topology, 'NE_NAME', 'USM')
with pd.option_context('display.max_rows', None, 'display.max_columns', None):
	print(df_vc)
df_vc.to_string()
from tabulate import tabulate
df_vcto_markdown()
df_vc.to_markdown()
from io import StringIO
import prettytable   
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
###### iFast DB Details   ###########
# IP address of the MySQL database server
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
df_db = pd.read_sql_query("SELECT * FROM iFAST.Topology_Test", conn)
df_db.head()
os.getcwd()
os.listdir()
os.listdir("/home/sieluser/Topology/Combined_Topology_Files')
os.listdir("/home/sieluser/Topology/Combined_Topology_Files")
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240804.csv", dtype=str)
df_new.head()
df.shape
df_new.shape
df_db.shape
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().fillna(""); dfnew = df_new.copy().fillna("")
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna('')
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().fillna(""); dfnew = df_new.copy().fillna("")
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna('')
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
	return df_chg, df_add
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().fillna(""); dfnew = df_new.copy().fillna("")
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna('')
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
    return df_chg, df_add
df1, df2 = compare_df(df_db, df_new, 'NE_NAME')
df_db = df.db.astype(str)
df_db = df_db.astype(str)
df1, df2 = compare_df(df_db, df_new, 'NE_NAME')
df1
df1, df2 = compare_df(df_db.drop(['Modified_Time']), df_new.drop(['Modified_Time']), 'NE_NAME')
df_db.columns
df_new.columns
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_new.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df1.shape
df2.shape
df2.head()
None==None
df_new.head()
df_topology = df_new.copy()
df_topology['NE_NAME'] = df_topology['NE_NAME'].apply(lambda x: x.strip("\\t"))
df_topology.shape
df_topology.head()
df_topology.fillna(None, inplace=True)
np
import numpy as np
df_topology = df_topology.replace([np.nan],[None])
df_db = df_db.replace([np.nan], [None])
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo']
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD ']]
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD ']
df2.head()
df_topology
df_topology = df_topology.drop_duplicates(subset = ["NE_NAME"])
del_query = "TRUNCATE TABLE iFAST.Topology_Test"
cur.execute(del_query)
conn.commit()
write_query = (f'INSERT IGNORE INTO iFAST.Topology_Test VALUES ({("%s,"*len(df_topology.columns)).rstrip(",")})')
cur.executemany(write_query, df_topology.values.tolist())
conn.commit()
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD']
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD'].loc['before']
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD'].loc['after']
df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD'].loc['before']==df1.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD'].loc['after']
df1.head()
df1.index
df1.shape
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().replace([np.nan], [None]); dfnew = df_new.copy().replace([np.nan], [None])
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna(np.nan).replace([np.nan], [None])
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
    return df_chg, df_add
df_db.head()
df_topology
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df1.shape
df2
None==None
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().replace([np.nan],[None]).replace([np.nan], [None]); dfnew = df_new.copy().fillna(np.nan).replace([np.nan], [None])
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna(np.nan).replace([np.nan], [None])
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
    return df_chg, df_add
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.shape
df2.shape
df1.head()
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().fillna(""); dfnew = df_new.copy().fillna("")
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna('')
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
    return df_chg, df_add
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.shape
df1.head()
def compare_df(df_old, df_new, index_column):
    dfold = df_old.copy().fillna(np.nan).replace([np.nan], [None]); dfnew = df_new.copy().fillna(np.nan).replace([np.nan], [None])
    for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
    for col in dfnew.columns:
        dfnew[col] = dfnew[col].str.casefold()
    iold = set(dfold[index_column])
    inew = set(dfnew[index_column])
    added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
    dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
    dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
    df_chg  = dfold.compare(dfnew).fillna(np.nan).replace([np.nan], [None])
    df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
    return df_chg, df_add
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df_db = pd.read_sql_query("SELECT * FROM iFAST.Topology_Tes", conn)
df_db = pd.read_sql_query("SELECT * FROM iFAST.Topology_Test", conn)
os.getcwd()
os.listdir()
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_topology.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df2.head()
df_db.drop(['Modified_Time'], axis=1)
df_topology.drop(['Modified_Time'], axis=1)
df1, df2 = compare_df(df_db.drop(['Modified_Time'], axis=1), df_new.drop(['Modified_Time'], axis=1), 'NE_NAME')
df1.head()
df2.head()
df2.shape
df1.shape
df_old = df_db.drop(['Modified_Time'], axis=1).copy()
df_today = df_new.copy()
df_new = df_new.drop(['Modified_Time'], axis=1).copy()
dfnew = df_new.drop(['Modified_Time'], axis=1).copy()
dfnew = df_new.copy()
for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold(
)
dfold = df_db.drop(['Modified_Time'], axis=1).copy()
for col in dfold.columns:
        dfold[col] = dfold[col].str.casefold()
for col in dfnew.columns:
	dfnew[col] = dfnew[col].str.casefold()
index_column = "NE_NAME"
dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True)
df_chg  = dfold.compare(dfnew)
dfold = df_db.drop(['Modified_Time'], axis=1).copy()
dfnew = df_new.copy()
for col in dfold.columns:
	dfold[col] = dfold[col].str.casefold()
for col in dfnew.columns:
	dfnew[col] = dfnew[col].str.casefold()
iold = set(dfold[index_column])
inew = set(dfnew[index_column])
added = inew - iold ;filt_added = dfnew[index_column].isin(added) ; df_add = dfnew[ filt_added ] ; dfnew = dfnew[ ~ filt_added ]
    deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
deled = iold - inew ;filt_deled = dfold[index_column].isin(deled) ; df_del = dfold[ filt_deled ] ; dfold = dfold[ ~ filt_deled ]
dfold.set_index(index_column, inplace=True) ; dfold.sort_index(inplace=True)
dfnew.set_index(index_column, inplace=True) ; dfnew.sort_index(inplace=True) 
 dfold
df_chg  = dfold.compare(dfnew)
df_chg
df_old
dfold.fillna("", inplace=True)
dfnew.fillna(inplace=True)
dfnew.fillna("",inplace=True)
df_chg  = dfold.compare(dfnew)
df_chg
dfold.loc[dfold['NE_NAME']=='05690013012_5gdu_cambridge_donnelly_field_ma-wsbo']
dfold.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo']
dfold.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD']
dfnew.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'CHANNEL_CARD']
dfnew.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'USM']
dfold.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'USM']
dfold.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'REL_VERSION']
dfnew.loc['05690013012_5gdu_cambridge_donnelly_field_ma-wsbo', 'REL_VERSION']
df_chag.columns
df_chg.columns
df_chg  = dfold.compare(dfnew).fillna(np.nan).replace([np.nan], [None])
df_chg
df_chg.rename(columns={'self':'before', 'other':'after'}, level=-1, inplace=True) 
df_chg.columns
def df_change_summary(df_change):
    df = pd.DataFrame()
    for col in df_change.columns.levels[0]:
        df_copy = df_change[col]
        df_copy['Parameter'] = col
        df = pd.concat([df, df_copy])
        df = df.replace([""], [None])
        df = df.dropna(subset = ['before', 'after'], how='all')
    return df
df_chg = df_change_summary(df_chg)
df_chg
df_db.head()
df_new.head()
conn.close()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
###### iFast DB Details   ###########
# IP address of the MySQL database server
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
df_db = pd.read_sql_query("SELECT * from iFAST.netowrk_topology", conn)
df_db = pd.read_sql_query("SELECT * from iFAST.network_topology", conn)
df_db
os.getcwd()
os.listdir()
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df_new.head()
for usm in df_usm in df_new.groupby("USM"):
	if usm in df_db['USM'].unique():
		usm_del_query = f"DELETE FROM iFAST.network_topology WHERE USM = '{usm}'"
		cur.execute(usm_del_query)
		conn.commit()
		write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df_new.columns)).rstrip(",")})')
		cur.executemany(write_query, df_new.values.tolist())
	else:
		print(f"Not updating {usm} rows due to missing files in latest folder")
usm
for usm in df_usm in df_new.groupby("USM"):
	print(usm, df_usm)
df_new.groupby('USM')
for usm, df in df_new.groupby('USM'):
	print(usm)
for usm, df in df_new.groupby('USM'):
	print(usm, df)
for usm, df_new in df_new.groupby('USM'):
	print(usm, df_new)
for usm, df_new in df_new.groupby('USM'):
	if usm in df_db['USM'].unique():
		usm_del_query = f"DELETE FROM iFAST.network_topology WHERE USM = '{usm}'"
		cur.execute(usm_del_query)
		conn.commit()
		write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df_new.columns)).rstrip(",")})')
		cur.executemany(write_query, df_new.values.tolist())
		conn.commit()
	else:
		print(f"{usm}")
for usm, df_new in df_new.groupby('USM'):
	print(usm)
df_new.shape
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df_new.shape
for usm, df_new in df_new.groupby('USM'):
    if usm in df_db['USM'].unique():
        print(f"Deleting {usm} from network_topology table")
        usm_del_query = f"DELETE FROM iFAST.network_topology WHERE USM = '{usm}'"
        cur.execute(usm_del_query)
        conn.commit()
        print(f"Updating network_topology table with {usm} data")
        write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df_new.columns)).rstrip(",")})')
        cur.executemany(write_query, df_new.values.tolist())
        conn.commit()
        print("\n")
    else:
        print(f"{usm} not available in latest data")
        print("\n")
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
import numpy as np
df_new = df_new.replace([np.nan], [None])
for usm, df_new in df_new.groupby('USM'):
    if usm in df_db['USM'].unique():
        print(f"Deleting {usm} from network_topology table")
        usm_del_query = f"DELETE FROM iFAST.network_topology WHERE USM = '{usm}'"
        cur.execute(usm_del_query)
        conn.commit()
        print(f"Updating network_topology table with {usm} data")
        write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df_new.columns)).rstrip(",")})')
        cur.executemany(write_query, df_new.values.tolist())
        conn.commit()
        print("\n")
    else:
        print(f"{usm} not available in latest data")
        print("\n")
df_new.USM.unique()
df_new = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df_new.USM.unique()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
final_df_list = []
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
today_dir
for f in glob.glob(f'{topology_dir}/*'):
	print(f, "-----------", f.split("/")[-1].strip("-topology.csv"))
for f in glob.glob(f'{pwd}{today_dir}/*'):
	print(f, "-----------", f.split("/")[-1].strip("-topology.csv"))
f = '/home/sieluser/Topology/20240805/Twinsburg-topology.csv'
f.split("/")[-1]
f.split("/")[-1].strip("-topology.csv")
f.split("/")[-1].replace("-topology.csv", "")
df_db.head()
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240804.csv", dtype=str)
np
import numpy as np
df = df.replace([np.nan], [None])
df.head(0
)
df.head()
cur
write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df.columns)).rstrip(",")})')
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
cur.executemany(write_query, df.values.tolist())
conn.commit()
df.head()
conn.close()
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
cur.executemany(write_query, df.values.tolist())
conn.commit()
import os
import pandas as pd
os.listdir()
df = pd.read_csv("
df = pd.read_csv("Combined_Topology_20240806.csv", dtype=str)
df['USM'].unique()
cd ..
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
import numpy as np
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
###### iFast DB Details   ###########
# IP address of the MySQL database server
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
df = pd.read_csv(f"{pwd}Combined_Topology_Files/Combined_Topology_{today_dir}.csv", dtype=str)
df= df.replace([np.nan], [None])
df_db = pd.read_sql_query("SELECT * FROM iFAST.network_topology", conn)
df_db.shape
df.shape
set(df_db['USM']).intersection(set(df['USM']))
len(set(df_db['USM']).intersection(set(df['USM'])))
cur.execute("DELETE FROM iFAST.network_topology WHERE USM = 'Twinsbur'"
)
conn.commit()
cur.execute("DELETE FROM iFAST.network_topology WHERE USM = 'ColoradoSprin'")
conn.commit()
set(9df_db['USM'])
set(df_db['USM'])
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
pwd = "/home/sieluser/Topology/"
today_dir = datetime.now().strftime("%Y%m%d")
###### iFast DB Details   ###########
# IP address of the MySQL database server
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
usm_del_query = f"DELETE FROM iFAST.network_topology WHERE USM ='Sacramen'"
cur.execute(usm_del_query)
conn.commit()
import os
import pandas as pd
from datetime import datetime
import glob
import paramiko
import time
import pymysql
import re
import numpy as np
os.getcwd()
df = pd.read_csv(/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df = pd.read_csv("/home/sieluser/Topology/Combined_Topology_Files/Combined_Topology_20240805.csv", dtype=str)
df['USM'].unique()
df_usm = df.loc[df['USM']=='Sacramento']
df_usm
df_usm = df_usm.replace([np.nan], [None])
Host = "127.0.0.1"
# Username and PW of the database server
User = "admin"; Password = "@DBadmin123"
# Connection to the server
conn = pymysql.connect(host=Host, user=User, password=Password, database="iFAST")
print("Connection established to iFast Server")
#conn = pymysql.connect(host=Host, user=User, password=Password, database="testdb_flagged")
# Create a cursor object
cur = conn.cursor()
write_query = (f'INSERT IGNORE INTO iFAST.network_topology VALUES ({("%s,"*len(df_usm.columns)).rstrip(",")})')
write_query
cur.executemany(write_query, df_usm.values.tolist())
conn.commit()
conn.close()
import os
import pandas as pd
os.listdir()
df = pd.read_csv("Combined_Topology_20240806.csv", dtype=str)
df.head()
df['NE_ID'].value_counts()
df.loc[df['NE_ID']=='DU_1520027']
df.loc[df['NE_ID']=='DU_1520017']
df.loc[df['NE_ID']=='DU_1520014']
df.loc[df['NE_ID']=='DU_1510014']
import os
import pandas as pd
df = pd.read_csv("Combined_Topology_20240806.csv", dtype=str)
df.head()
vc = df['NE_ID'].value_counts()
vc[vc.index>1]
vc
vc[vc>1].index
len(vc[vc>1].index)
import os
import pandas as pd
df = pd.read_csv("Combined_Topology_20240806.csv", dtype=str)
df.head()
df.groupby(['NE_ID', 'USM']).size()
vc = df.groupby(['NE_ID', 'USM']).size()
vc = vc[vc>1]
vc
vc.index
df1 = df.reset_index(['NE_ID', 'USM'], drop=True)
df.head()
df1 = df.set_index(['NE_ID', 'USM'], drop=True)
df1.head()
df1.loc[('ACPF_56000100','Branchburg2A')]
df1.loc[vc]
